{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892571ee",
   "metadata": {},
   "source": [
    "## Prerequisites and installation instructions\n",
    "\n",
    "This notebook uses `bluegraph.downstream.similarity` module for building similarity indices (on embedded nodes, for example). In order to run it the Facebook :code:`Faiss` library must be installed separately. Please, see [Faiss installation instructions](https://github.com/facebookresearch/faiss/blob/master/INSTALL.md).\n",
    "\n",
    "\n",
    "We recommend using `conda` for installing `faiss`. For example:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge faiss\n",
    "```\n",
    "\n",
    "or as a part of a new `conda` environment:\n",
    "\n",
    "```\n",
    "conda create --name <your_environment> -c conda-forge faiss\n",
    "conda activate <your_environment>\n",
    "```\n",
    "\n",
    " \n",
    "This notebook illustrates some graph representation learning techniques and use `stellargraph` as a backend. BlueGraph and the set of dependecies supporting `stellargraph` can be installed using:\n",
    "\n",
    " ```\n",
    " pip install bluegraph[stellargraph]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a149a",
   "metadata": {},
   "source": [
    "# Node embedding and downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import mixture\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7161156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluegraph.core import PandasPGFrame\n",
    "from bluegraph.preprocess.generators import CooccurrenceGenerator\n",
    "from bluegraph.preprocess.encoders import ScikitLearnPGEncoder\n",
    "\n",
    "from bluegraph.core.embed.embedders import GraphElementEmbedder\n",
    "from bluegraph.backends.stellargraph import StellarGraphNodeEmbedder\n",
    "\n",
    "from bluegraph.downstream import (EmbeddingPipeline,\n",
    "                                  transform_to_2d,\n",
    "                                  plot_2d,\n",
    "                                  get_classification_scores)\n",
    "from bluegraph.downstream.similarity import (FaissSimilarityIndex,\n",
    "                                             SimilarityProcessor,\n",
    "                                             NodeSimilarityProcessor)\n",
    "from bluegraph.downstream.node_classification import NodeClassifier\n",
    "from bluegraph.downstream.link_prediction import (generate_negative_edges,\n",
    "                                                  EdgePredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f5d57",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec994a8",
   "metadata": {},
   "source": [
    "Fist, we read the source dataset with mentions of entities in different paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db48ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = pd.read_csv(\"../data/labeled_entity_occurrence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b25cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique paper/seciton/paragraph identifiers\n",
    "mentions = mentions.rename(columns={\"occurrence\": \"paragraph\"})\n",
    "number_of_paragraphs = len(mentions[\"paragraph\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759929a",
   "metadata": {},
   "source": [
    "We will also load a dataset that contains definitions of entities and their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf7da7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "entity_data = pd.read_csv(\"../data/entity_types_defs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc33fd",
   "metadata": {},
   "source": [
    "### Generation of a co-occurrence graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2f43d",
   "metadata": {},
   "source": [
    "We first create a graph whose nodes are entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = PandasPGFrame()\n",
    "entity_nodes = mentions[\"entity\"].unique()\n",
    "graph.add_nodes(entity_nodes)\n",
    "graph.add_node_types({n: \"Entity\" for n in entity_nodes})\n",
    "\n",
    "entity_props = entity_data.rename(columns={\"entity\": \"@id\"}).set_index(\"@id\")\n",
    "graph.add_node_properties(entity_props[\"entity_type\"], prop_type=\"category\")\n",
    "graph.add_node_properties(entity_props[\"definition\"], prop_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_prop = pd.DataFrame({\"paragraphs\": mentions.groupby(\"entity\").aggregate(set)[\"paragraph\"]})\n",
    "graph.add_node_properties(paragraph_prop, prop_type=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes(raw_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2141e65",
   "metadata": {},
   "source": [
    "For each node we will add the `frequency` property that counts the total number of paragraphs where the entity was mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = graph._nodes[\"paragraphs\"].apply(len)\n",
    "frequencies.name = \"frequency\"\n",
    "graph.add_node_properties(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes(raw_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c09404",
   "metadata": {},
   "source": [
    "Now, for constructing co-occurrence network we will select only 1000 most frequent entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_include = graph._nodes.nlargest(1000, \"frequency\").index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fb15c",
   "metadata": {},
   "source": [
    "The `CooccurrenceGenerator` class allows us to generate co-occurrence edges from overlaps in node property values or edge (or edge properties). In this case we consider the `paragraph` node property and construct co-occurrence edges from overlapping sets of paragraphs. In addition, we will compute some co-occurrence statistics: total co-occurrence frequency and normalized pointwise mutual information (NPMI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ce417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "generator = CooccurrenceGenerator(graph.subgraph(nodes=nodes_to_include))\n",
    "paragraph_cooccurrence_edges = generator.generate_from_nodes(\n",
    "    \"paragraphs\", total_factor_instances=number_of_paragraphs,\n",
    "    compute_statistics=[\"frequency\", \"npmi\"],\n",
    "    parallelize=True, cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = paragraph_cooccurrence_edges[\"npmi\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba406a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_cooccurrence_edges = paragraph_cooccurrence_edges[paragraph_cooccurrence_edges[\"npmi\"] > cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef9d15",
   "metadata": {},
   "source": [
    "We add generated edges to the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._edges = paragraph_cooccurrence_edges\n",
    "graph.edge_prop_as_numeric(\"frequency\")\n",
    "graph.edge_prop_as_numeric(\"npmi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc091b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges(raw_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807ce7a",
   "metadata": {},
   "source": [
    "Recall that we have generated edges only for the 1000 most frequent entities, the rest of the entities will be isolated (having no incident edges). Let us remove all the isolated nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f52379",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.remove_node_properties(\"paragraphs\")\n",
    "graph.remove_edge_properties(\"common_factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff33597",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.remove_isolated_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c358754",
   "metadata": {},
   "source": [
    "Next, we save the generated co-occurrence graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e455b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.export_json(\"../data/cooccurrence_graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = PandasPGFrame.load_json(\"../data/cooccurrence_graph.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b40051",
   "metadata": {},
   "source": [
    "### Node feature extraction\n",
    "\n",
    "We extract node features from entity definitions using the `tfidf` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaeca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ScikitLearnPGEncoder(\n",
    "    node_properties=[\"definition\"],\n",
    "    text_encoding_max_dimension=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c43e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transformed_graph = encoder.fit_transform(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2082d",
   "metadata": {},
   "source": [
    "We can have a glance at the vocabulary that the encoder constructed for the 'definition' property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1052e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = encoder._node_encoders[\"definition\"].model.vocabulary_\n",
    "list(vocabulary.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5e6bc",
   "metadata": {},
   "source": [
    "We will add additional properties to our transformed graph corresponding to the entity type labels. We will also add NPMI as an edge property to this transformed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e47908",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_graph.add_node_properties(\n",
    "    graph.get_node_property_values(\"entity_type\"))\n",
    "transformed_graph.add_edge_properties(\n",
    "    graph.get_edge_property_values(\"npmi\"), prop_type=\"numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_graph.nodes(raw_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8edf526",
   "metadata": {},
   "source": [
    "## Node embedding and downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf42a8",
   "metadata": {},
   "source": [
    "### Node embedding using StellarGraph\n",
    "\n",
    "Using `StellarGraphNodeEmbedder` we construct three different embeddings of our transformed graph corresponding to different embedding techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7350a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node2vec_embedder = StellarGraphNodeEmbedder(\n",
    "    \"node2vec\", edge_weight=\"npmi\", embedding_dimension=64, length=10, number_of_walks=20)\n",
    "node2vec_embedding = node2vec_embedder.fit_model(transformed_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0949611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attri2vec_embedder = StellarGraphNodeEmbedder(\n",
    "    \"attri2vec\", feature_vector_prop=\"features\",\n",
    "    length=5, number_of_walks=10,\n",
    "    epochs=10, embedding_dimension=128, edge_weight=\"npmi\")\n",
    "attri2vec_embedding = attri2vec_embedder.fit_model(transformed_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_dgi_embedder = StellarGraphNodeEmbedder(\n",
    "    \"gcn_dgi\", feature_vector_prop=\"features\", epochs=250, embedding_dimension=512)\n",
    "gcn_dgi_embedding = gcn_dgi_embedder.fit_model(transformed_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61461db6",
   "metadata": {},
   "source": [
    "The `fit_model` method produces a dataframe of the following shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5846da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d9827",
   "metadata": {},
   "source": [
    "Let us add the embedding vectors obtained using different models as node properties of our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_graph.add_node_properties(\n",
    "    node2vec_embedding.rename(columns={\"embedding\": \"node2vec\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_graph.add_node_properties(\n",
    "    attri2vec_embedding.rename(columns={\"embedding\": \"attri2vec\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_graph.add_node_properties(\n",
    "    gcn_dgi_embedding.rename(columns={\"embedding\": \"gcn_dgi\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84123e14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transformed_graph.nodes(raw_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b569be",
   "metadata": {},
   "source": [
    "### Plotting the embeddings\n",
    "\n",
    "Having produced the embedding vectors, we can project them into a 2D space using dimensionality reduction techniques such as TSNE (t-distributed Stochastic Neighbor Embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8596e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_2d = transform_to_2d(transformed_graph._nodes[\"node2vec\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720423de",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_2d = transform_to_2d(transformed_graph._nodes[\"attri2vec\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_dgi_2d = transform_to_2d(transformed_graph._nodes[\"gcn_dgi\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b9e0c",
   "metadata": {},
   "source": [
    "We can now plot these 2D vectors using the `plot_2d` util provided by `bluegraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3100bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=node2vec_2d, label_prop=\"entity_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=attri2vec_2d, label_prop=\"entity_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3f4de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=gcn_dgi_2d, label_prop=\"entity_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc668dc",
   "metadata": {},
   "source": [
    "### Node similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62295d99",
   "metadata": {},
   "source": [
    "We would like to be able to search for similar nodes using the computed vector embeddings. For this we can use the `NodeSimilarityProcessor` interfaces provided as a part of `bluegraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c99d5",
   "metadata": {},
   "source": [
    "We construct similarity processors for different embeddings and query top 10 most similar nodes to the terms `glucose` and `covid-19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_l2 = NodeSimilarityProcessor(transformed_graph, \"node2vec\", similarity=\"euclidean\")\n",
    "node2vec_cosine = NodeSimilarityProcessor(\n",
    "    transformed_graph, \"node2vec\", similarity=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_l2.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_cosine.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_l2 = NodeSimilarityProcessor(transformed_graph, \"attri2vec\")\n",
    "attri2vec_cosine = NodeSimilarityProcessor(\n",
    "    transformed_graph, \"attri2vec\", similarity=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_l2.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af3aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attri2vec_cosine.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b151ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_l2 = NodeSimilarityProcessor(transformed_graph, \"gcn_dgi\")\n",
    "gcn_cosine = NodeSimilarityProcessor(\n",
    "    transformed_graph, \"gcn_dgi\", similarity=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_l2.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cab8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_cosine.get_neighbors([\"glucose\", \"covid-19\"], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c14f42",
   "metadata": {},
   "source": [
    "### Node clustering\n",
    "\n",
    "We can cluster nodes according to their node embeddings. Often such clustering helps to reveal the community structure encoded in the underlying networks.\n",
    "\n",
    "In this example we will use the `BayesianGaussianMixture` model provided by the scikit-learn to cluster the nodes according to different embeddings into 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847aece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_graph.get_node_property_values(\"node2vec\").to_list()\n",
    "gmm = mixture.BayesianGaussianMixture(n_components=N, covariance_type='full').fit(X)\n",
    "node2vec_clusters = gmm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93afbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_graph.get_node_property_values(\"attri2vec\").to_list()\n",
    "gmm = mixture.BayesianGaussianMixture(n_components=5, covariance_type='full').fit(X)\n",
    "attri2vec_clusters = gmm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_graph.get_node_property_values(\"gcn_dgi\").to_list()\n",
    "gmm = mixture.BayesianGaussianMixture(n_components=5, covariance_type='full').fit(X)\n",
    "gcn_dgi_clusters = gmm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cebd1e",
   "metadata": {},
   "source": [
    "Below we inspect the most frequent cluster members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cacb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_members(clusters, N):\n",
    "    for i in range(N):\n",
    "        df = transformed_graph._nodes.iloc[np.where(clusters == i)]\n",
    "        df.loc[:, \"frequency\"] = df.index.map(lambda x: graph._nodes.loc[x, \"frequency\"])\n",
    "        print(f\"#{i}: \", \", \".join(df.nlargest(10, columns=[\"frequency\"]).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_members(node2vec_clusters, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_members(attri2vec_clusters, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c957f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_members(gcn_dgi_clusters, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8080bd",
   "metadata": {},
   "source": [
    "We can also use the previously `plot_2d` util and color our 2D nore representation according to the clusters they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=node2vec_2d, labels=node2vec_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=attri2vec_2d, labels=attri2vec_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(transformed_graph, vectors=gcn_dgi_2d, labels=gcn_dgi_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a0916",
   "metadata": {},
   "source": [
    "### Node classification\n",
    "\n",
    "Another downstream task that we would like to perform is node classification. We would like to automatically assign entity types according to their node embeddings. For this we will build predictive models for entity type prediction based on:\n",
    "\n",
    "- Only node features\n",
    "- Node2vec embeddings (only structure)\n",
    "- Attri2vec embeddings (structure and node features)\n",
    "- GCN Deep Graph Infomax embeddings (structure and node features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76073cc",
   "metadata": {},
   "source": [
    "First of all, we split the graph nodes into the train and the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes, test_nodes = model_selection.train_test_split(\n",
    "    transformed_graph.nodes(), train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e601ff8",
   "metadata": {},
   "source": [
    "Now we use the `NodeClassifier` interface to create our classification models. As the base model we will use the linear SVM classifier (`LinearSVC`) provided by `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_classifier = NodeClassifier(LinearSVC(), feature_vector_prop=\"features\")\n",
    "features_classifier.fit(transformed_graph, train_elements=train_nodes, label_prop=\"entity_type\")\n",
    "features_pred = features_classifier.predict(transformed_graph, predict_elements=test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_classifier = NodeClassifier(LinearSVC(), feature_vector_prop=\"node2vec\")\n",
    "node2vec_classifier.fit(transformed_graph, train_elements=train_nodes, label_prop=\"entity_type\")\n",
    "node2vec_pred = node2vec_classifier.predict(transformed_graph, predict_elements=test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc61db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_classifier = NodeClassifier(LinearSVC(), feature_vector_prop=\"attri2vec\")\n",
    "attri2vec_classifier.fit(transformed_graph, train_elements=train_nodes, label_prop=\"entity_type\")\n",
    "attri2vec_pred = attri2vec_classifier.predict(transformed_graph, predict_elements=test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_dgi_classifier = NodeClassifier(LinearSVC(), feature_vector_prop=\"gcn_dgi\")\n",
    "gcn_dgi_classifier.fit(transformed_graph, train_elements=train_nodes, label_prop=\"entity_type\")\n",
    "gcn_dgi_pred = gcn_dgi_classifier.predict(transformed_graph, predict_elements=test_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6299922",
   "metadata": {},
   "source": [
    "Let us have a look at the scores of different node classification models we have produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17265ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = transformed_graph._nodes.loc[test_nodes, \"entity_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1580f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_classification_scores(true_labels, features_pred, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_scores(true_labels, node2vec_pred, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_scores(true_labels, attri2vec_pred, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97045c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_scores(true_labels, gcn_dgi_pred, multiclass=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79cf60",
   "metadata": {},
   "source": [
    "## Link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb984430",
   "metadata": {},
   "source": [
    "Finally, we would like to use the produced node embeddings to predict the existance of edges. This downstream task is formulated as follows: given a pair of nodes and their embedding vectors, is there an edge between these nodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd9c68",
   "metadata": {},
   "source": [
    "As the first step of the edges prediciton task we will generate false edges for training (node pairs that don't have edges between them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6aab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_edges = generate_negative_edges(transformed_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a009718a",
   "metadata": {},
   "source": [
    "We will now split both true and false edges into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16defb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_edges, true_test_edges = model_selection.train_test_split(\n",
    "    transformed_graph.edges(), train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1007b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_train_edges, false_test_edges = model_selection.train_test_split(\n",
    "    false_edges, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7352de",
   "metadata": {},
   "source": [
    "And, finally, we will use the `EdgePredictor` interface to build our model (using `LinearSVC` as before and the Hadamard product as the binary operator between the embedding vectors for the source and the target nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EdgePredictor(LinearSVC(), feature_vector_prop=\"node2vec\",\n",
    "                      operator=\"hadamard\", directed=False)\n",
    "model.fit(transformed_graph, true_train_edges, negative_samples=false_train_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.hstack([\n",
    "    np.ones(len(true_test_edges)),\n",
    "    np.zeros(len(false_test_edges))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daebbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(transformed_graph, true_test_edges + false_test_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0635d",
   "metadata": {},
   "source": [
    "Let us have a look at the obtained scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3732c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_classification_scores(true_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61df05a",
   "metadata": {},
   "source": [
    "## Creating and saving embedding pipelines\n",
    "\n",
    "`bluegraph` allows to create emebedding pipelines (using the `EmbeddingPipeline` class) that represent a useful wrapper around a sequence of steps necessary to produce embeddings and compute point similarities. In the example below we create a pipeline for producing `attri2vec` node embeddings and computing their cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f778669",
   "metadata": {},
   "source": [
    "We first create an encoder object that will be used in our pipeline as a preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_encoder = ScikitLearnPGEncoder(\n",
    "    node_properties=[\"definition\"], text_encoding_max_dimension=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12497b51",
   "metadata": {},
   "source": [
    "We then create an embedder object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 128\n",
    "params = {\n",
    "    \"length\": 5,\n",
    "    \"number_of_walks\": 10,\n",
    "    \"epochs\": 5,\n",
    "    \"embedding_dimension\": D\n",
    "}\n",
    "attri2vec_embedder = StellarGraphNodeEmbedder(\n",
    "    \"attri2vec\", feature_vector_prop=\"features\", edge_weight=\"npmi\", **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0460720",
   "metadata": {},
   "source": [
    "And finally we create a pipeline object. Note that in the code below we use the `SimilarityProcessor` interface and not `NodeSimilarityProcessor`, as we have done it previously. We use this lower abstraction level interface, because the `EmbeddingPipeline` is designed to work with any embedding models (not only node embedding models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_pipeline = EmbeddingPipeline(\n",
    "    preprocessor=definition_encoder,\n",
    "    embedder=attri2vec_embedder,\n",
    "    similarity_processor=SimilarityProcessor(\n",
    "        FaissSimilarityIndex(\n",
    "            similarity=\"cosine\", dimension=D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2ab36",
   "metadata": {},
   "source": [
    "We run the fitting process, which given the input data:\n",
    "1. fits the encoder\n",
    "2. transforms the data\n",
    "3. fits the embedder\n",
    "4. produces the embedding table\n",
    "5. fits the similarity processor index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_pipeline.run_fitting(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767b8a6",
   "metadata": {},
   "source": [
    "How we can save our pipeline to the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_pipeline.save(\n",
    "    \"../data/attri2vec_test_model\",\n",
    "    compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13c8aa",
   "metadata": {},
   "source": [
    "And we can load the pipeline back into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = EmbeddingPipeline.load(\n",
    "    \"../data/attri2vec_test_model.zip\",\n",
    "    embedder_interface=GraphElementEmbedder,\n",
    "    embedder_ext=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b392d",
   "metadata": {},
   "source": [
    "We can use `retrieve_embeddings` and `get_similar_points` methods of the pipeline object to respectively get embedding vectors and top most similar nodes for the input nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.retrieve_embeddings([\"covid-19\", \"glucose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef589ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pipeline.retrieve_embeddings([\"covid-19\", \"glucose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_neighbors(existing_points=[\"covid-19\", \"glucose\"], k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_bg",
   "language": "python",
   "name": "clean_bg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
